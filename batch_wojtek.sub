#!/bin/sh
#BSUB -q gpua100
#BSUB -J WhisperTranscript
#BSUB -n 4
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 08:00
#BSUB -R "span[hosts=1]"
#BSUB -R "rusage[mem=5GB]"
#BSUB -o gpu_%J.out
# -- end of LSF options --

# Print information on gpu
nvidia-smi

#Load the necessary modules
module load cuda/10.2
module load python3/3.9.11
module load ffmpeg/5.0.1

# Activate the virtual environment -> link to your own before starting 
source /zhome/10/4/164561/whisper_venv/bin/activate

MODELS="tiny base small medium tiny.en base.en small.en medium.en large"
# MODELS="large"

# python3 /zhome/10/4/164561/Whisper-transcribe-tool/src/fine_tune.py
for model in $MODELS
do
    python3 /zhome/10/4/164561/Whisper-transcribe-tool/src/main.py model=$model benchmark=fleurs benchmark.language='en' benchmark.dataset_language='en_us'
done